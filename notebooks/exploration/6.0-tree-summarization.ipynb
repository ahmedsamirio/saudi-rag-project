{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.indexing import get_multivector_retriever, get_parent_child_splits\n",
    "from src.generation import QA_SYSTEM_PROMPT, QA_PROMPT, LLAMA_PROMPT_TEMPLATE, MIXTRAL_PROMPT_TEMPLATE\n",
    "from src.generation import get_model, format_docs, get_rag_chain\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from src.ingestion import load_pdf\n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "import uuid\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_7532\\1562872242.py:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  DATA_PATH = 'D:\\Ahmed\\saudi-rag-project\\data'\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'D:\\Ahmed\\saudi-rag-project\\data'\n",
    "RAW_DOCS_PATH = os.path.join(DATA_PATH, \"raw\")\n",
    "CHROMA_PATH = os.path.join(DATA_PATH, \"chroma\")\n",
    "INTERIM_DATA_PATH = os.path.join(DATA_PATH, \"interim\")\n",
    "\n",
    "EMBEDDING_MODEL_NAMES = [\n",
    "    \"intfloat/multilingual-e5-small\", \n",
    "    \"intfloat/multilingual-e5-base\", \n",
    "    \"text-embedding-3-small\", \n",
    "    \"text-embedding-3-large\",\n",
    "    \"text-embedding-ada-002\"\n",
    " ]\n",
    "MODEL_NAMES = [\"meta-llama/Llama-3-8b-chat-hf\", \"meta-llama/Llama-3-70b-chat-hf\", \"mistralai/Mixtral-8x22B-Instruct-v0.1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persistent_client = chromadb.PersistentClient(path=CHROMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each context the model obtains it should create a summary answer\n",
    "\n",
    "# All of the answers should be input back into the model to create a better answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
