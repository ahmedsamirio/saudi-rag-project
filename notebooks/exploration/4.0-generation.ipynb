{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation import get_model, format_docs, QA_SYSTEM_PROMPT, QA_PROMPT, LLAMA_PROMPT_TEMPLATE\n",
    "from src.indexing import get_multivector_retriever\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "persistent_client = chromadb.PersistentClient(path='../../data/chroma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_20804\\3935730633.py:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  save_path = 'D:\\Ahmed\\saudi-rag-project\\data'\n"
     ]
    }
   ],
   "source": [
    "save_path = 'D:\\Ahmed\\saudi-rag-project\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_CHUNK_SIZE = 1200\n",
    "PARENT_CHUNK_OVERLAP = 400\n",
    "\n",
    "CHILD_CHUNK_SIZE = 300\n",
    "CHILD_CHUNK_OVERLAP = 0\n",
    "\n",
    "EMBEDDING_MODEL_NAME = 'intfloat/multilingual-e5-small'\n",
    "\n",
    "COLLECTION_NAME = f\"PARENT_{PARENT_CHUNK_SIZE}_{PARENT_CHUNK_OVERLAP}_CHILD_{CHILD_CHUNK_SIZE}_{CHILD_CHUNK_OVERLAP}_{EMBEDDING_MODEL_NAME}\"\n",
    "COLLECTION_NAME = COLLECTION_NAME.replace('/', '_').replace('-', '_')\n",
    "\n",
    "retriever = get_multivector_retriever(persistent_client, EMBEDDING_MODEL_NAME, COLLECTION_NAME, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "QA_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Answer in Arabic only.\"\"\"\n",
    "\n",
    "LLAMA_PROMPT_TEMPLATE = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{user_message}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "qa_prompt_template = PromptTemplate.from_template(LLAMA_PROMPT_TEMPLATE.format(system_prompt=QA_SYSTEM_PROMPT, user_message=QA_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Answer in Arabic only.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuestion: {question} \\nContext: {context}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAnswer:\")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-3-70b-chat-hf\"\n",
    "llm = get_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | qa_prompt_template\n",
    "    | llm.bind(stop=[\"<|eot_id|>\"])\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' صافي الربح بعد الزكاة للمجموعة عام 2021 هو 587.7 مليون ريال سعودي.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"ما هو اجمالي صافي الربح بعد الزكاة للمجموعة عام 2021؟\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saudi-rag-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
